{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1 Camera projection Matrix [30 pts]\n",
    "Study the `Projection and Dolly Zoom` notebook (`dolly_zoom.py` or at [link](https://colab.research.google.com/drive/1LlOwsp5zCV-dIfZRlmWMJfbeArUTclQo) ) and finish the following tasks.\n",
    "\n",
    "(a) Write a function `rotY()` which takes an angle theta (in radian) and outputs the 3D rotation matrix of\n",
    "rotating by theta about the y-axis (right-hand rule). You may refer to this Wikipedia entry: https:\n",
    "//en.wikipedia.org/wiki/Rotation matrix#Basic rotations After you are done, refer to the starter code to\n",
    "generate and submit cube.gif of a cube rotating around itself. (5 pts)"
   ],
   "id": "520c083f0c52f4c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:11:11.738983Z",
     "start_time": "2024-09-20T13:11:07.886494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from resources.hw1_starter import *\n",
    "\n",
    "# Problem 1.(a)\n",
    "def rotY(theta_radian):\n",
    "    # takes an angle theta (in radian) and outputs the 3D rotation matrix of\n",
    "    # rotating by theta about the y-axis (right-hand rule).\n",
    "    # theta_radian: R=np.eye(3)\n",
    "    return np.array([\n",
    "        [ np.cos(theta_radian), 0, np.sin(theta_radian)],\n",
    "        [ 0,                    1, 0                   ],\n",
    "        [-np.sin(theta_radian), 0, np.cos(theta_radian)]\n",
    "    ])\n",
    "\n",
    "generate_gif()\n",
    "\n"
   ],
   "id": "2444d5744650a35e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(b) Similarly, write a function `rotX()` which rotates about the x-axis. Let $θ = \\frac{\\pi}{4}$, consider the following\n",
    "two transformations:\n",
    "1. rotX(theta), followed by rotY(theta)\n",
    "2. rotY(theta), followed by rotX(theta)\n",
    "Using `renderCube()` in the same way, plot the resulting view of the cube from two transformations.\n",
    "Are 3D rotation matrices commutative? (5 pts)"
   ],
   "id": "e39dc89ebaa4ddbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:11:13.213975Z",
     "start_time": "2024-09-20T13:11:13.199849Z"
    }
   },
   "cell_type": "code",
   "source": "# for the rest of the code of Task 1, Please check in the hw1_starter.py. ",
   "id": "397c23074569b15f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(c) Combine rotX() and rotY(), choose an appropriate order and a pair of parameters so that renderCube() draws\n",
    "a projection of the cube where one diagonal of the cube is projected to a single point, as shown\n",
    "in Figure 1 (left). Report the order and parameters you choose. (10 pts)\n",
    "> Hint: The diagonal of the cube rotates together with the cube. When it projects to a single point in\n",
    "2D, it is horizontal and perpendicular to the camera plane in 3D. You can either make a mathematical\n",
    "calculation or perform a numerical search."
   ],
   "id": "9c9dc4259b5b07fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(d) Implement an orthographic camera by either adding a branch to function projectLines(), or refer to it\n",
    "and write a new one. Then plot the same rotated cube in the previous part with this orthographic\n",
    "camera. It should look like Figure 1 (right). (10 pts)\n",
    "![](Fig/1.png \"Figure 1: The diagonal of a cube projected to a single point\")"
   ],
   "id": "770356d44345e508"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1101a45fa0f98f4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 Prokudin-Gorskii: Color from grayscale photographs [50 pts]",
   "id": "2f347b5ead627a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this part, you are tasked with implementing the dream of Russian photographer, Sergei Mikhailovich\n",
    "Prokudin-Gorskii (1863-1944), via a project invented by Russian-American vision researcher, Alexei A.\n",
    "Efros (1975-present). Sergei was a visionary who believed in a future with color photography (which we\n",
    "now take for granted). During his lifetime, he traveled across the Russian Empire taking photographs\n",
    "through custom color filters at the whim of the czar. To capture color for the photographers of the future,\n",
    "he decided to take three separate black-and-white pictures of every scene, each with a red, green, or blue\n",
    "color filter in front of the camera. His hope was that you, as a student in the future, would come along and\n",
    "produce beautiful color images by combining his 3 separate, filtered images."
   ],
   "id": "3f7e6456417d671e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1: Combine (5 pts) \n",
    "We will provide you with a folder of Prokudin-Gorskii’s black-and-white\n",
    "(grayscale) image composites (prokudin-gorskii/ in the assignment zip). Each composite (alter- natively\n",
    "triple-framed image or triptych) contains three grayscale photos preserved from the early 1900s. The\n",
    "composite looks like a three-panel vertical comic strip, with each grayscale photo in the composite\n",
    "positioned vertically above one another. These photos represent images captured with a blue, green, and\n",
    "red filter. Choose a single composite from this folder (your favorite) and write a program in Python that\n",
    "takes the three grayscale panels and simply stacks them across the third color channel dimension to\n",
    "produce a single, colored image. We expect this stacked photo to look wonky and unaligned- fixing this is\n",
    "what you will do in Task 2. Make sure to save your images as RGB instead of BGR and include them in\n",
    "your report.\n",
    "Specifically: Write a function that loads a grayscale tripled-framed image from prokudin-gorskii/ with\n",
    "something like plt.imread(), chops it vertically into thirds, then saves a color image with each third as the\n",
    "correct color channel. Save the output colored image in your report."
   ],
   "id": "16da28902e83455a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:11:14.612873Z",
     "start_time": "2024-09-20T13:11:14.566405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "folder_path = './resources/prokudin-gorskii'\n",
    "file_names = os.listdir('./resources/prokudin-gorskii')\n",
    "\n",
    "if not os.path.isdir(os.path.join('./Homework_result/Problem_2',\"Task_1\")):\n",
    "    os.mkdir(os.path.join('./Homework_result/Problem_2',\"Task_1\"))\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if file_name.lower().endswith(('.jpg')):\n",
    "        try:\n",
    "            image = np.array(Image.open(file_path).convert('L'))\n",
    "            \n",
    "            print(f\"Successful open：{file_name}\")\n",
    "            \n",
    "            split_height = image.shape[0] // 3\n",
    "            \n",
    "            image  = image[ : split_height * 3, :]\n",
    "            \n",
    "            retVal = np.dstack((\n",
    "                image[2 * split_height :                 , :],  # R\n",
    "                image[split_height     : 2 * split_height, :],  # G\n",
    "                image[0                :     split_height, :]   # B\n",
    "            ))\n",
    "            \n",
    "            # Image.fromarray(retVal.astype(np.uint8)).save()\n",
    "            \n",
    "            Image.fromarray(retVal).save(os.path.join('./Homework_result/Problem_2',\"Task_1\", file_name))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Cannot open {file_name}：{e}\")\n",
    "    else:\n",
    "        print(f\"Skip：{file_name}, not an image.\")\n",
    "        "
   ],
   "id": "13087b48279257a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful open：00125v.jpg\n",
      "Successful open：00149v.jpg\n",
      "Successful open：00153v.jpg\n",
      "Successful open：00351v.jpg\n",
      "Successful open：00398v.jpg\n",
      "Successful open：01112v.jpg\n",
      "Skip：Task_1, not an image.\n",
      "Skip：Task_2, not an image.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2: Alignment (25 pts) \n",
    "As you will have noticed, the photos are misaligned due to inadvertent\n",
    "jostling of the camera between each shot. Your second task is to fix this. You need to search over possible\n",
    "pixel offsets in the range of [-15, 15] to find the best alignment for the different R, G, and B channels.\n",
    "The simplest way is to keep one channel fixed, say R, and align the G and B channels to it by searching\n",
    "over the offset range both horizontally and vertically. Pick the alignment that maximizes a similarity\n",
    "metric (of your choice) between the channels. One such measure is dot product, i.e, R G. Another is\n",
    "normalized cross- correlation, which is simply the dot product between the L2 normalized R and G\n",
    "vectors. After writing this function, run it on all of the images in prokudin-gorskii/ and also on ’efros\n",
    "tableau.jpg’, so Professor Efros can have his photo restored to color. Include these aligned images and the\n",
    "offsets in your report. For full credit, your report needs to include properly aligned images - find a\n",
    "similarity metric that will accomplish this."
   ],
   "id": "3463bea4277f7bd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:11:30.094110Z",
     "start_time": "2024-09-20T13:11:14.954495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def ncc(image1, image2):\n",
    "    image1_mean = np.mean(image1)\n",
    "    image2_mean = np.mean(image2)\n",
    "    numerator = np.sum((image1 - image1_mean) * (image2 - image2_mean))\n",
    "    denominator = np.sqrt(np.sum((image1 - image1_mean) ** 2) * np.sum((image2 - image2_mean) ** 2))\n",
    "    return numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "def align_channel(ref_channel, target_channel, search_range):\n",
    "    max_ncc = -1\n",
    "    best_dx = 0\n",
    "    best_dy = 0\n",
    "    for dx in range(-search_range, search_range + 1):\n",
    "        for dy in range(-search_range, search_range + 1):\n",
    "            shifted_channel = np.roll(target_channel, shift=(dy, dx), axis=(0, 1))\n",
    "            h, w = ref_channel.shape\n",
    "            crop_margin = search_range\n",
    "            ref_crop = ref_channel[crop_margin:-crop_margin, crop_margin:-crop_margin]\n",
    "            shifted_crop = shifted_channel[crop_margin:-crop_margin, crop_margin:-crop_margin]\n",
    "            current_ncc = ncc(ref_crop, shifted_crop)\n",
    "            if current_ncc > max_ncc:\n",
    "                max_ncc = current_ncc\n",
    "                best_dx = dx\n",
    "                best_dy = dy\n",
    "    return best_dx, best_dy\n",
    "\n",
    "folder_path = './resources/prokudin-gorskii'\n",
    "output_folder = os.path.join('./Homework_result/Problem_2',\"Task_2\")\n",
    "\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if file_name.lower().endswith('.jpg'):\n",
    "        try:\n",
    "            image = np.array(Image.open(file_path).convert('L'))\n",
    "            print(f\"Processing：{file_name}\")\n",
    "            \n",
    "            height = image.shape[0] // 3\n",
    "            image = image[:height*3, :] \n",
    "            B = image[0:height, :]\n",
    "            G = image[height:2*height, :]\n",
    "            R = image[2*height:3*height, :]\n",
    "            \n",
    "            search_range = 15 \n",
    "            \n",
    "            dx_g, dy_g = align_channel(R, G, search_range)\n",
    "            print(f\"Best offset for G channel: dx={dx_g}, dy={dy_g}\")\n",
    "            G_aligned = np.roll(G, shift=(dy_g, dx_g), axis=(0, 1))\n",
    "            \n",
    "            dx_b, dy_b = align_channel(R, B, search_range)\n",
    "            print(f\"Best offset for B channel: dx={dx_b}, dy={dy_b}\")\n",
    "            B_aligned = np.roll(B, shift=(dy_b, dx_b), axis=(0, 1))\n",
    "            \n",
    "            aligned_image = np.dstack((R, G_aligned, B_aligned))\n",
    "            aligned_image = aligned_image.astype(np.uint8)\n",
    "            \n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            Image.fromarray(aligned_image).save(output_path)\n",
    "            print(f\"Saved aligned image to: {output_path}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Cannot process {file_name}：{e}\\n\")\n",
    "    else:\n",
    "        print(f\"Skip：{file_name}, not an image.\\n\")\n"
   ],
   "id": "f134c3effb9a1887",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing：00125v.jpg\n",
      "Best offset for G channel: dx=1, dy=-4\n",
      "Best offset for B channel: dx=-1, dy=-10\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_2\\00125v.jpg\n",
      "\n",
      "Processing：00149v.jpg\n",
      "Best offset for G channel: dx=0, dy=-5\n",
      "Best offset for B channel: dx=-1, dy=-9\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_2\\00149v.jpg\n",
      "\n",
      "Processing：00153v.jpg\n",
      "Best offset for G channel: dx=-2, dy=-7\n",
      "Best offset for B channel: dx=0, dy=-15\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_2\\00153v.jpg\n",
      "\n",
      "Processing：00351v.jpg\n",
      "Best offset for G channel: dx=-1, dy=-9\n",
      "Best offset for B channel: dx=-1, dy=-13\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_2\\00351v.jpg\n",
      "\n",
      "Processing：00398v.jpg\n",
      "Best offset for G channel: dx=-1, dy=-6\n",
      "Best offset for B channel: dx=-4, dy=-11\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_2\\00398v.jpg\n",
      "\n",
      "Processing：01112v.jpg\n",
      "Best offset for G channel: dx=-2, dy=-5\n",
      "Best offset for B channel: dx=-2, dy=-6\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_2\\01112v.jpg\n",
      "\n",
      "Skip：Task_1, not an image.\n",
      "\n",
      "Skip：Task_2, not an image.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Specifically**: Write a function to align the 3 channels of the image produced by Task 1. This function\n",
    "should output the (x,y) offsets required for shifting two of the color channels with respect to third. The\n",
    "third channel might then have a (0,0) offset. Save the newly aligned images from prokudin-gorskii/ and\n",
    "’efros tableau.jpg’ in your report, along with the offsets for each color channel. Report the similarity\n",
    "metric you choose.\n",
    "\n",
    "**Hint**: To offset the channels while keeping the same dimensions among them, you can use either np.roll()\n",
    "to roll over boundaries, or np.pad() for padding."
   ],
   "id": "7f3e7c5d063af9f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3: Pyramid (20 pts) \n",
    "For very large offsets (and high-resolution images), comparing all the alignments\n",
    "for a broad range of displacements (e.g. [-30, 30]) can be computationally intensive. We will have\n",
    "you implement a recursive version of your algorithm that starts by estimating an image’s alignment on a\n",
    "low-resolution version of itself, before refining it on higher resolutions. To implement this, you will build\n",
    "a two-level image pyramid. To do this, you must first scale the triple-frame images down by a factor of 2\n",
    "(both the width and height should end up halved). Starting with your shrunk, coarse images, execute your\n",
    "alignment from Task 2 over the following range of offsets [-15, 15]. Choose the best alignment based on\n",
    "your similarity metric and treat it as the new current alignment. Then in the full resolution images, use\n",
    "this new current alignment as a starting place to again run the alignment from Task 2 in a small range [-\n",
    "15, 15]. Run this Pyramid task on the ’seoul tableau.jpg’ and ’vancouver tableau.jpg’ images. If your\n",
    "course project goes well.\n",
    "\n",
    "**Specifically**: Use cv2.resize() to shrink each image in the triptych. Use your code from Task 2 to align\n",
    "them and get the intermediate offset. Shift the original images accordingly and align again at full\n",
    "resolution. Report the intermediate offset (at the coarse resolution), the next offset at the full resolution,\n",
    "and what the overall total offset was that includes both of these. Save the aligned images in color in your\n",
    "report.\n",
    "\n",
    "**Hint**: If you’re struggling, use a different color channel as your anchor!\n",
    "\n",
    "**Report** You must submit a report that includes the offsets, color output images, and description required\n",
    "above. Your description should be such that a reader could implement what you’ve done after reading your\n",
    "report."
   ],
   "id": "2c36986ba72635ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:14:59.661011Z",
     "start_time": "2024-09-20T13:11:30.142812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2  # 导入 OpenCV 库用于图像缩放\n",
    "\n",
    "def ncc(image1, image2):\n",
    "    image1_mean = np.mean(image1)\n",
    "    image2_mean = np.mean(image2)\n",
    "    numerator = np.sum((image1 - image1_mean) * (image2 - image2_mean))\n",
    "    denominator = np.sqrt(np.sum((image1 - image1_mean) ** 2) * np.sum((image2 - image2_mean) ** 2))\n",
    "    return numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "def align_channel(ref_channel, target_channel, search_range, start_dx=0, start_dy=0):\n",
    "    max_ncc = -1\n",
    "    best_dx = start_dx\n",
    "    best_dy = start_dy\n",
    "    h, w = ref_channel.shape\n",
    "    crop_margin = search_range\n",
    "    ref_crop = ref_channel[crop_margin:-crop_margin, crop_margin:-crop_margin]\n",
    "    \n",
    "    for dx in range(start_dx - search_range, start_dx + search_range + 1):\n",
    "        for dy in range(start_dy - search_range, start_dy + search_range + 1):\n",
    "            shifted_channel = np.roll(target_channel, shift=(dy, dx), axis=(0, 1))\n",
    "            shifted_crop = shifted_channel[crop_margin:-crop_margin, crop_margin:-crop_margin]\n",
    "            current_ncc = ncc(ref_crop, shifted_crop)\n",
    "            if current_ncc > max_ncc:\n",
    "                max_ncc = current_ncc\n",
    "                best_dx = dx\n",
    "                best_dy = dy\n",
    "    return best_dx, best_dy\n",
    "\n",
    "folder_path = './resources/'\n",
    "output_folder = os.path.join('./Homework_result/Problem_2',\"Task_3\")\n",
    "\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "file_names = [\n",
    "    'seoul_tableau.jpg',\n",
    "    'vancouver_tableau.jpg',\n",
    "    'efros_tableau.jpg'\n",
    "]\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if file_name.lower().endswith('.jpg'):\n",
    "        try:\n",
    "            # 读取原始图像并转换为灰度图像\n",
    "            image = np.array(Image.open(file_path).convert('L'))\n",
    "            print(f\"Processing：{file_name}\")\n",
    "            \n",
    "            # 将图像分割为三个通道\n",
    "            height = image.shape[0] // 3\n",
    "            image = image[:height*3, :] \n",
    "            B = image[0:height, :]\n",
    "            G = image[height:2*height, :]\n",
    "            R = image[2*height:3*height, :]\n",
    "            \n",
    "            # 使用 cv2.resize() 将通道缩小一半\n",
    "            R_small = cv2.resize(R, (R.shape[1] // 2, R.shape[0] // 2), interpolation=cv2.INTER_AREA)\n",
    "            G_small = cv2.resize(G, (G.shape[1] // 2, G.shape[0] // 2), interpolation=cv2.INTER_AREA)\n",
    "            B_small = cv2.resize(B, (B.shape[1] // 2, B.shape[0] // 2), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            # 在缩小的图像上进行粗略对齐\n",
    "            search_range_coarse = 15\n",
    "            print(\"Performing coarse alignment on downsampled images...\")\n",
    "            dx_g_coarse, dy_g_coarse = align_channel(R_small, G_small, search_range_coarse)\n",
    "            dx_b_coarse, dy_b_coarse = align_channel(R_small, B_small, search_range_coarse)\n",
    "            print(f\"Coarse alignment offsets for G channel: dx={dx_g_coarse}, dy={dy_g_coarse}\")\n",
    "            print(f\"Coarse alignment offsets for B channel: dx={dx_b_coarse}, dy={dy_b_coarse}\")\n",
    "            \n",
    "            # 将粗略偏移量放大两倍，作为高分辨率对齐的起始偏移量\n",
    "            dx_g_initial = dx_g_coarse * 2\n",
    "            dy_g_initial = dy_g_coarse * 2\n",
    "            dx_b_initial = dx_b_coarse * 2\n",
    "            dy_b_initial = dy_b_coarse * 2\n",
    "            \n",
    "            # 在高分辨率的图像上进行精细对齐\n",
    "            search_range_fine = 15\n",
    "            print(\"Refining alignment on full-resolution images...\")\n",
    "            dx_g_fine, dy_g_fine = align_channel(R, G, search_range_fine, start_dx=dx_g_initial, start_dy=dy_g_initial)\n",
    "            dx_b_fine, dy_b_fine = align_channel(R, B, search_range_fine, start_dx=dx_b_initial, start_dy=dy_b_initial)\n",
    "            print(f\"Fine alignment offsets for G channel: dx={dx_g_fine}, dy={dy_g_fine}\")\n",
    "            print(f\"Fine alignment offsets for B channel: dx={dx_b_fine}, dy={dy_b_fine}\")\n",
    "            \n",
    "            # 计算总的偏移量\n",
    "            total_dx_g = dx_g_fine\n",
    "            total_dy_g = dy_g_fine\n",
    "            total_dx_b = dx_b_fine\n",
    "            total_dy_b = dy_b_fine\n",
    "            print(f\"Total offsets for G channel: dx={total_dx_g}, dy={total_dy_g}\")\n",
    "            print(f\"Total offsets for B channel: dx={total_dx_b}, dy={total_dy_b}\")\n",
    "            \n",
    "            # 对齐通道\n",
    "            G_aligned = np.roll(G, shift=(total_dy_g, total_dx_g), axis=(0, 1))\n",
    "            B_aligned = np.roll(B, shift=(total_dy_b, total_dx_b), axis=(0, 1))\n",
    "            \n",
    "            # 合并对齐后的通道\n",
    "            aligned_image = np.dstack((R, G_aligned, B_aligned))\n",
    "            aligned_image = aligned_image.astype(np.uint8)\n",
    "            \n",
    "            # 保存对齐后的图像\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            Image.fromarray(aligned_image).save(output_path)\n",
    "            print(f\"Saved aligned image to: {output_path}\\n\")\n",
    "            \n",
    "            # 报告偏移量\n",
    "            print(\"Offset Summary:\")\n",
    "            print(f\"G channel - Coarse Offset: dx={dx_g_coarse}, dy={dy_g_coarse}\")\n",
    "            print(f\"G channel - Fine Offset Adjustment: dx={dx_g_fine - dx_g_initial}, dy={dy_g_fine - dy_g_initial}\")\n",
    "            print(f\"G channel - Total Offset: dx={total_dx_g}, dy={total_dy_g}\")\n",
    "            print(f\"B channel - Coarse Offset: dx={dx_b_coarse}, dy={dy_b_coarse}\")\n",
    "            print(f\"B channel - Fine Offset Adjustment: dx={dx_b_fine - dx_b_initial}, dy={dy_b_fine - dy_b_initial}\")\n",
    "            print(f\"B channel - Total Offset: dx={total_dx_b}, dy={total_dy_b}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Cannot process {file_name}：{e}\\n\")\n",
    "    else:\n",
    "        print(f\"Skip：{file_name}, not an image.\\n\")\n"
   ],
   "id": "c00533d0f774344a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing：seoul_tableau.jpg\n",
      "Performing coarse alignment on downsampled images...\n",
      "Coarse alignment offsets for G channel: dx=3, dy=0\n",
      "Coarse alignment offsets for B channel: dx=1, dy=-1\n",
      "Refining alignment on full-resolution images...\n",
      "Fine alignment offsets for G channel: dx=6, dy=0\n",
      "Fine alignment offsets for B channel: dx=1, dy=-2\n",
      "Total offsets for G channel: dx=6, dy=0\n",
      "Total offsets for B channel: dx=1, dy=-2\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_3\\seoul_tableau.jpg\n",
      "\n",
      "Offset Summary:\n",
      "G channel - Coarse Offset: dx=3, dy=0\n",
      "G channel - Fine Offset Adjustment: dx=0, dy=0\n",
      "G channel - Total Offset: dx=6, dy=0\n",
      "B channel - Coarse Offset: dx=1, dy=-1\n",
      "B channel - Fine Offset Adjustment: dx=-1, dy=0\n",
      "B channel - Total Offset: dx=1, dy=-2\n",
      "\n",
      "Processing：vancouver_tableau.jpg\n",
      "Performing coarse alignment on downsampled images...\n",
      "Coarse alignment offsets for G channel: dx=11, dy=-1\n",
      "Coarse alignment offsets for B channel: dx=6, dy=4\n",
      "Refining alignment on full-resolution images...\n",
      "Fine alignment offsets for G channel: dx=22, dy=-1\n",
      "Fine alignment offsets for B channel: dx=12, dy=8\n",
      "Total offsets for G channel: dx=22, dy=-1\n",
      "Total offsets for B channel: dx=12, dy=8\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_3\\vancouver_tableau.jpg\n",
      "\n",
      "Offset Summary:\n",
      "G channel - Coarse Offset: dx=11, dy=-1\n",
      "G channel - Fine Offset Adjustment: dx=0, dy=1\n",
      "G channel - Total Offset: dx=22, dy=-1\n",
      "B channel - Coarse Offset: dx=6, dy=4\n",
      "B channel - Fine Offset Adjustment: dx=0, dy=0\n",
      "B channel - Total Offset: dx=12, dy=8\n",
      "\n",
      "Processing：efros_tableau.jpg\n",
      "Performing coarse alignment on downsampled images...\n",
      "Coarse alignment offsets for G channel: dx=5, dy=0\n",
      "Coarse alignment offsets for B channel: dx=15, dy=-3\n",
      "Refining alignment on full-resolution images...\n",
      "Fine alignment offsets for G channel: dx=10, dy=0\n",
      "Fine alignment offsets for B channel: dx=45, dy=-11\n",
      "Total offsets for G channel: dx=10, dy=0\n",
      "Total offsets for B channel: dx=45, dy=-11\n",
      "Saved aligned image to: ./Homework_result/Problem_2\\Task_3\\efros_tableau.jpg\n",
      "\n",
      "Offset Summary:\n",
      "G channel - Coarse Offset: dx=5, dy=0\n",
      "G channel - Fine Offset Adjustment: dx=0, dy=0\n",
      "G channel - Total Offset: dx=10, dy=0\n",
      "B channel - Coarse Offset: dx=15, dy=-3\n",
      "B channel - Fine Offset Adjustment: dx=15, dy=-5\n",
      "B channel - Total Offset: dx=45, dy=-11\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Color Spaces and illuminance [20 pts]\n",
    "\n",
    "The same color may look different under different lighting conditions. Images indoor.png and outdoor.png are two photos of a\n",
    "same Rubik’s cube under different illuminances2.\n",
    "1. Load the images and plot their R, G, B channels separately as grayscale images using plt.imshow() (beware of\n",
    "normalization). Then convert them into LAB color space using cv2.cvtColor() and plot the three channels again. Include the\n",
    "plots in your report. (5 pts)\n",
    "2. How do you know the illuminance change is better separated in LAB color space? (5 pts)\n",
    "3. Choose two different lighting conditions and take two photos of a non-specular object. Try to make the same color look\n",
    "as different as possible (a large distance on AB plane in LAB space). Below is an example of two photos of the same piece\n",
    "of paper, taken in the basement and by the window respectively.\n",
    "\n",
    "\n",
    "Submit the two images with names im1.jpg and im2.jpg, both cropped and scaled to 256X256. Under the same folder, also\n",
    "submit a file info.txt that contains two lines: Line 1 contains four integers x1,y1,x2,y2 where we will take a 32X32 patch\n",
    "around the coordinate on each image and compare colors. (You can use plt.imshow() and plt.show() to bring up a window\n",
    "where you can select pixel with coordinates.) Line 2 is a description of the lighting conditions that you choose. An example of\n",
    "this file is provided for you in the folder. (10 pts)"
   ],
   "id": "72477f938601c2ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T01:29:24.260855Z",
     "start_time": "2024-09-21T01:29:19.343722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 定义一个函数来绘制 RGB 和 LAB 通道并保存在同一个图像中\n",
    "def plot_channels(image_rgb, image_lab, title_prefix, save_path):\n",
    "    R_channel = image_rgb[:, :, 0]\n",
    "    G_channel = image_rgb[:, :, 1]\n",
    "    B_channel = image_rgb[:, :, 2]\n",
    "\n",
    "    L_channel = image_lab[:, :, 0]\n",
    "    A_channel = image_lab[:, :, 1]\n",
    "    B_channel_lab = image_lab[:, :, 2]\n",
    "\n",
    "    # 归一化处理 LAB 通道\n",
    "    L_channel_normalized = cv2.normalize(L_channel, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    A_channel_normalized = cv2.normalize(A_channel, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    B_channel_lab_normalized = cv2.normalize(B_channel_lab, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    # 绘制\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # 绘制 RGB 通道\n",
    "    plt.subplot(3, 3, 1)\n",
    "    plt.imshow(R_channel, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(f'{title_prefix} - Red')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 2)\n",
    "    plt.imshow(G_channel, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(f'{title_prefix} - Green')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 3)\n",
    "    plt.imshow(B_channel, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(f'{title_prefix} - Blue')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 绘制 LAB 通道（原始数据）\n",
    "    plt.subplot(3, 3, 4)\n",
    "    plt.imshow(L_channel, cmap='gray', vmin=0, vmax=100)\n",
    "    plt.title(f'{title_prefix} - L (Original)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 5)\n",
    "    plt.imshow(A_channel, cmap='gray', vmin=-128, vmax=127)\n",
    "    plt.title(f'{title_prefix} - A (Original)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 6)\n",
    "    plt.imshow(B_channel_lab, cmap='gray', vmin=-128, vmax=127)\n",
    "    plt.title(f'{title_prefix} - B (Original)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 绘制 LAB 通道（归一化后）\n",
    "    plt.subplot(3, 3, 7)\n",
    "    plt.imshow(L_channel_normalized, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(f'{title_prefix} - L (Normalized)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 8)\n",
    "    plt.imshow(A_channel_normalized, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(f'{title_prefix} - A (Normalized)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 9)\n",
    "    plt.imshow(B_channel_lab_normalized, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(f'{title_prefix} - B (Normalized)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. 加载图像并分别绘制其 R、G、B 和 LAB 通道\n",
    "# 加载室内和室外图像（请确保图像文件位于当前目录）\n",
    "indoor_img = cv2.imread('./resources/indoor.png')\n",
    "outdoor_img = cv2.imread('./resources/outdoor.png')\n",
    "\n",
    "# 将图像从 BGR 转换为 RGB（OpenCV 默认使用 BGR 格式）\n",
    "indoor_img_rgb = cv2.cvtColor(indoor_img, cv2.COLOR_BGR2RGB)\n",
    "outdoor_img_rgb = cv2.cvtColor(outdoor_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 将图像从 RGB 转换为 LAB 色彩空间\n",
    "indoor_lab = cv2.cvtColor(indoor_img_rgb, cv2.COLOR_RGB2LAB)\n",
    "outdoor_lab = cv2.cvtColor(outdoor_img_rgb, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "# 绘制室内和室外图像的 RGB 和 LAB 通道\n",
    "plot_channels(indoor_img_rgb, indoor_lab, 'Task1_Indoor', './task1_indoor_channels.png')\n",
    "plot_channels(outdoor_img_rgb, outdoor_lab, 'Task1_Outdoor', './task1_outdoor_channels.png')\n",
    "\n",
    "# 2. 对室内和室外图像进行润色\n",
    "# 选择图像的中心坐标\n",
    "x1, y1 = 44, 44\n",
    "x2, y2 = 44, 44\n",
    "\n",
    "print(f\"Indoor image center coordinate: x1={x1}, y1={y1}\")\n",
    "print(f\"Outdoor image center coordinate: x2={x2}, y2={y2}\")\n",
    "\n",
    "# 提取 32x32 的色块\n",
    "indoor_patch_lab = indoor_lab[y1-10:y1+10, x1-10:x1+10, :]\n",
    "outdoor_patch_lab = outdoor_lab[y2-10:y2+10, x2-10:x2+10, :]\n",
    "\n",
    "indoor_patch_rgb = indoor_img_rgb[y1-10:y1+10, x1-10:x1+10, :]\n",
    "outdoor_patch_rgb = outdoor_img_rgb[y2-10:y2+10, x2-10:x2+10, :]\n",
    "\n",
    "# 计算色块的平均 LAB 值\n",
    "mean_indoor_lab = np.mean(indoor_patch_lab.reshape(-1, 3), axis=0)\n",
    "mean_outdoor_lab = np.mean(outdoor_patch_lab.reshape(-1, 3), axis=0)\n",
    "\n",
    "# 计算色块的平均 RGB 值\n",
    "mean_indoor_rgb = np.mean(indoor_patch_rgb.reshape(-1, 3), axis=0)\n",
    "mean_outdoor_rgb = np.mean(outdoor_patch_rgb.reshape(-1, 3), axis=0)\n",
    "\n",
    "print(f\"Indoor image patch average LAB value: {mean_indoor_lab}\")\n",
    "print(f\"Outdoor image patch average LAB value: {mean_outdoor_lab}\")\n",
    "\n",
    "print(f\"Indoor image patch average RGB value: {mean_indoor_rgb}\")\n",
    "print(f\"Outdoor image patch average RGB value: {mean_outdoor_rgb}\")\n",
    "\n",
    "# 使用 LAB 进行颜色调整\n",
    "a_diff_lab = mean_indoor_lab[1] - mean_outdoor_lab[1]\n",
    "b_diff_lab = mean_indoor_lab[2] - mean_outdoor_lab[2]\n",
    "\n",
    "outdoor_lab_adjusted = outdoor_lab.astype(np.float32)\n",
    "outdoor_lab_adjusted[:, :, 1] += a_diff_lab\n",
    "outdoor_lab_adjusted[:, :, 2] += b_diff_lab\n",
    "outdoor_lab_adjusted[:, :, 1] = np.clip(outdoor_lab_adjusted[:, :, 1], 0, 255)\n",
    "outdoor_lab_adjusted[:, :, 2] = np.clip(outdoor_lab_adjusted[:, :, 2], 0, 255)\n",
    "outdoor_lab_adjusted = outdoor_lab_adjusted.astype(np.uint8)\n",
    "outdoor_rgb_adjusted_lab = cv2.cvtColor(outdoor_lab_adjusted, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "# 使用 RGB 进行颜色调整\n",
    "rgb_diff = mean_indoor_rgb - mean_outdoor_rgb\n",
    "outdoor_rgb_adjusted_rgb = np.clip(outdoor_img_rgb + rgb_diff, 0, 255).astype(np.uint8)\n",
    "\n",
    "# 显示并保存调整前后的图像\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(indoor_img_rgb)\n",
    "plt.title('Original Indoor')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(outdoor_img_rgb)\n",
    "plt.title('Original Outdoor')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(outdoor_rgb_adjusted_lab)\n",
    "plt.title('LAB Adjusted Outdoor')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.imshow(outdoor_rgb_adjusted_rgb)\n",
    "plt.title('RGB Adjusted Outdoor')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.imshow(indoor_img_rgb)\n",
    "plt.title('Comparison Indoor')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./task2_outdoor_vs_indoor_adjusted_rgb_lab.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3. 对自己的图像进行同样的操作\n",
    "# 加载自己的图像\n",
    "im1 = cv2.imread('./resources/im1.png')\n",
    "im2 = cv2.imread('./resources/im2.png')\n",
    "\n",
    "# 将图像从 BGR 转换为 RGB\n",
    "im1_rgb = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "im2_rgb = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 将图像缩放到 256x256\n",
    "im1_resized = cv2.resize(im1_rgb, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "im2_resized = cv2.resize(im2_rgb, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# 将图像从 RGB 转换为 LAB 色彩空间\n",
    "im1_lab = cv2.cvtColor(im1_resized, cv2.COLOR_RGB2LAB)\n",
    "im2_lab = cv2.cvtColor(im2_resized, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "# 绘制自己的图像的 RGB 和 LAB 通道\n",
    "plot_channels(im1_resized, im1_lab, 'Task3_im1', './task3_im1_channels.png')\n",
    "plot_channels(im2_resized, im2_lab, 'Task3_im2', './task3_im2_channels.png')\n",
    "\n",
    "# 选择坐标点\n",
    "x1, y1 = 101, 136\n",
    "x2, y2 = 100, 134\n",
    "\n",
    "print(f\"im1.png coordinate: x1={x1}, y1={y1}\")\n",
    "print(f\"im2.png coordinate: x2={x2}, y2={y2}\")\n",
    "\n",
    "# 提取 32x32 的色块\n",
    "patch1_lab = im1_lab[y1-16:y1+16, x1-16:x1+16, :]\n",
    "patch2_lab = im2_lab[y2-16:y2+16, x2-16:x2+16, :]\n",
    "\n",
    "patch1_rgb = im1_resized[y1-16:y1+16, x1-16:x1+16, :]\n",
    "patch2_rgb = im2_resized[y2-16:y2+16, x2-16:x2+16, :]\n",
    "\n",
    "# 计算色块的平均 LAB 值\n",
    "mean_lab1 = np.mean(patch1_lab.reshape(-1, 3), axis=0)\n",
    "mean_lab2 = np.mean(patch2_lab.reshape(-1, 3), axis=0)\n",
    "\n",
    "# 计算色块的平均 RGB 值\n",
    "mean_rgb1 = np.mean(patch1_rgb.reshape(-1, 3), axis=0)\n",
    "mean_rgb2 = np.mean(patch2_rgb.reshape(-1, 3), axis=0)\n",
    "\n",
    "print(f\"im1.png 色块的平均 LAB 值：{mean_lab1}\")\n",
    "print(f\"im2.png 色块的平均 LAB 值：{mean_lab2}\")\n",
    "\n",
    "print(f\"im1.png 色块的平均 RGB 值：{mean_rgb1}\")\n",
    "print(f\"im2.png 色块的平均 RGB 值：{mean_rgb2}\")\n",
    "\n",
    "# 使用 LAB 进行颜色调整\n",
    "a_diff_lab = mean_lab1[1] - mean_lab2[1]\n",
    "b_diff_lab = mean_lab1[2] - mean_lab2[2]\n",
    "\n",
    "im2_lab_adjusted = im2_lab.astype(np.float32)\n",
    "im2_lab_adjusted[:, :, 1] += a_diff_lab\n",
    "im2_lab_adjusted[:, :, 2] += b_diff_lab\n",
    "im2_lab_adjusted[:, :, 1] = np.clip(im2_lab_adjusted[:, :, 1], 0, 255)\n",
    "im2_lab_adjusted[:, :, 2] = np.clip(im2_lab_adjusted[:, :, 2], 0, 255)\n",
    "im2_lab_adjusted = im2_lab_adjusted.astype(np.uint8)\n",
    "im2_rgb_adjusted_lab = cv2.cvtColor(im2_lab_adjusted, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "# 使用 RGB 进行颜色调整\n",
    "rgb_diff = mean_rgb1 - mean_rgb2\n",
    "im2_rgb_adjusted_rgb = np.clip(im2_resized + rgb_diff, 0, 255).astype(np.uint8)\n",
    "\n",
    "# 显示调整前后的图像并保存\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(im1_resized)\n",
    "plt.title('Original im1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(im2_resized)\n",
    "plt.title('Original im2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(im2_rgb_adjusted_lab)\n",
    "plt.title('LAB Adjusted im2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.imshow(im2_rgb_adjusted_rgb)\n",
    "plt.title('RGB Adjusted im2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.imshow(im1_resized)\n",
    "plt.title('Comparison im1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./task3_im2_vs_im1_adjusted_rgb_lab.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ],
   "id": "9fe789adfed08ce8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indoor image center coordinate: x1=44, y1=44\n",
      "Outdoor image center coordinate: x2=44, y2=44\n",
      "Indoor image patch average LAB value: [131.925  127.5075 136.4925]\n",
      "Outdoor image patch average LAB value: [233.96  124.65  125.275]\n",
      "Indoor image patch average RGB value: [128.875  122.9175 108.8825]\n",
      "Outdoor image patch average RGB value: [221.3725 233.4225 236.5225]\n",
      "im1.png coordinate: x1=101, y1=136\n",
      "im2.png coordinate: x2=100, y2=134\n",
      "im1.png 色块的平均 LAB 值：[192.50976562 142.7734375  154.63964844]\n",
      "im2.png 色块的平均 LAB 值：[210.28417969 128.54003906 119.0546875 ]\n",
      "im1.png 色块的平均 RGB 值：[228.0546875  174.93457031 137.98144531]\n",
      "im2.png 色块的平均 RGB 值：[197.87695312 206.10449219 222.44335938]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T02:28:03.369252Z",
     "start_time": "2024-09-21T02:28:01.988117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_channels(image_rgb, image_lab, title_prefix, save_path, selected_coords=None):\n",
    "    R_channel = image_rgb[:, :, 0]\n",
    "    G_channel = image_rgb[:, :, 1]\n",
    "    B_channel = image_rgb[:, :, 2]\n",
    "\n",
    "    L_channel = image_lab[:, :, 0]\n",
    "    A_channel = image_lab[:, :, 1]\n",
    "    B_channel_lab = image_lab[:, :, 2]\n",
    "\n",
    "    # 绘制\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # 绘制 RGB 通道\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(R_channel, cmap='gray')\n",
    "    if selected_coords:\n",
    "        plt.scatter([selected_coords[0]], [selected_coords[1]], color='red', s=50)  # 标记坐标\n",
    "    plt.title(f'{title_prefix} - Red')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(G_channel, cmap='gray')\n",
    "    if selected_coords:\n",
    "        plt.scatter([selected_coords[0]], [selected_coords[1]], color='red', s=50)\n",
    "    plt.title(f'{title_prefix} - Green')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(B_channel, cmap='gray')\n",
    "    if selected_coords:\n",
    "        plt.scatter([selected_coords[0]], [selected_coords[1]], color='red', s=50)\n",
    "    plt.title(f'{title_prefix} - Blue')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 绘制 LAB 通道\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(L_channel, cmap='gray')\n",
    "    if selected_coords:\n",
    "        plt.scatter([selected_coords[0]], [selected_coords[1]], color='red', s=50)\n",
    "    plt.title(f'{title_prefix} - L')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(A_channel, cmap='gray')\n",
    "    if selected_coords:\n",
    "        plt.scatter([selected_coords[0]], [selected_coords[1]], color='red', s=50)\n",
    "    plt.title(f'{title_prefix} - A')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.imshow(B_channel_lab, cmap='gray')\n",
    "    if selected_coords:\n",
    "        plt.scatter([selected_coords[0]], [selected_coords[1]], color='red', s=50)\n",
    "    plt.title(f'{title_prefix} - B')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# 修改后的 process_images 函数，将选择的坐标可视化在原始图像上\n",
    "def process_images(img1_path, img2_path, x1, y1, x2, y2, output_path):\n",
    "    # 加载图像并转换为 RGB 和 LAB\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "\n",
    "    img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img1_lab = cv2.cvtColor(img1_rgb, cv2.COLOR_RGB2LAB)\n",
    "    img2_lab = cv2.cvtColor(img2_rgb, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "    # 提取色块\n",
    "    patch_size = 10  # 色块半径\n",
    "    img1_patch_lab = img1_lab[y1-patch_size:y1+patch_size, x1-patch_size:x1+patch_size, :]\n",
    "    img2_patch_lab = img2_lab[y2-patch_size:y2+patch_size, x2-patch_size:x2+patch_size, :]\n",
    "\n",
    "    img1_patch_rgb = img1_rgb[y1-patch_size:y1+patch_size, x1-patch_size:x1+patch_size, :]\n",
    "    img2_patch_rgb = img2_rgb[y2-patch_size:y2+patch_size, x2-patch_size:x2+patch_size, :]\n",
    "\n",
    "    # 使用 LAB 进行颜色和亮度调整\n",
    "    img2_lab_adjusted = adjust_lab(img2_lab, img1_patch_lab)\n",
    "    img2_rgb_adjusted_lab = cv2.cvtColor(img2_lab_adjusted, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    # 使用 RGB 进行颜色和亮度调整\n",
    "    img2_rgb_adjusted_rgb = adjust_rgb(img2_rgb, img1_patch_rgb)\n",
    "\n",
    "    # 显示并保存调整前后的图像\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(img1_rgb)\n",
    "    plt.scatter([x1], [y1], color='red', s=50)  # 标记选择的坐标\n",
    "    plt.title('Original Image 1 (Marked)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.imshow(img2_rgb)\n",
    "    plt.scatter([x2], [y2], color='red', s=50)  # 标记选择的坐标\n",
    "    plt.title('Original Image 2 (Marked)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.imshow(img2_rgb_adjusted_lab)\n",
    "    plt.title('LAB Adjusted Image 2')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.imshow(img2_rgb_adjusted_rgb)\n",
    "    plt.title('RGB Adjusted Image 2')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.imshow(img1_rgb)\n",
    "    plt.title('Comparison Image 1')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# 处理室内和室外图像，带有坐标标记\n",
    "process_images(\n",
    "    img1_path='./resources/indoor.png',\n",
    "    img2_path='./resources/outdoor.png',\n",
    "    x1=44, y1=44,\n",
    "    x2=44, y2=44,\n",
    "    output_path='./task2_outdoor_vs_indoor_adjusted_rgb_lab_marked.png'\n",
    ")\n",
    "\n",
    "# 处理自定义图像 im1 和 im2，带有坐标标记\n",
    "process_images(\n",
    "    img1_path='./resources/im1.png',\n",
    "    img2_path='./resources/im2.png',\n",
    "    x1=101, y1=136,\n",
    "    x2=100, y2=134,\n",
    "    output_path='./task3_im2_vs_im1_adjusted_rgb_lab_marked.png'\n",
    ")\n"
   ],
   "id": "c8470ef3933f0888",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:15:04.650741Z",
     "start_time": "2024-09-20T13:15:04.636710Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fc98fc354327e2e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:15:04.743453Z",
     "start_time": "2024-09-20T13:15:04.728938Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "85ed11d91dd162e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:15:04.820476Z",
     "start_time": "2024-09-20T13:15:04.806774Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3da064a1e45c0dcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1069db18cd857401"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
