{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1 Camera projection Matrix [30 pts]\n",
    "Study the `Projection and Dolly Zoom` notebook (`dolly_zoom.py` or at [link](https://colab.research.google.com/drive/1LlOwsp5zCV-dIfZRlmWMJfbeArUTclQo) ) and finish the following tasks.\n",
    "\n",
    "(a) Write a function `rotY()` which takes an angle theta (in radian) and outputs the 3D rotation matrix of\n",
    "rotating by theta about the y-axis (right-hand rule). You may refer to this Wikipedia entry: https:\n",
    "//en.wikipedia.org/wiki/Rotation matrix#Basic rotations After you are done, refer to the starter code to\n",
    "generate and submit cube.gif of a cube rotating around itself. (5 pts)"
   ],
   "id": "520c083f0c52f4c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# todo",
   "id": "2444d5744650a35e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(b) Similarly, write a function `rotX()` which rotates about the x-axis. Let $θ = \\frac{\\pi}{4}$, consider the following\n",
    "two transformations:\n",
    "1. rotX(theta), followed by rotY(theta)\n",
    "2. rotY(theta), followed by rotX(theta)\n",
    "Using `renderCube()` in the same way, plot the resulting view of the cube from two transformations.\n",
    "Are 3D rotation matrices commutative? (5 pts)"
   ],
   "id": "e39dc89ebaa4ddbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "397c23074569b15f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(c) Combine rotX() and rotY(), choose an appropriate order and a pair of parameters so that renderCube() draws\n",
    "a projection of the cube where one diagonal of the cube is projected to a single point, as shown\n",
    "in Figure 1 (left). Report the order and parameters you choose. (10 pts)\n",
    "> Hint: The diagonal of the cube rotates together with the cube. When it projects to a single point in\n",
    "2D, it is horizontal and perpendicular to the camera plane in 3D. You can either make a mathematical\n",
    "calculation or perform a numerical search."
   ],
   "id": "9c9dc4259b5b07fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(d) Implement an orthographic camera by either adding a branch to function projectLines(), or refer to it\n",
    "and write a new one. Then plot the same rotated cube in the previous part with this orthographic\n",
    "camera. It should look like Figure 1 (right). (10 pts)\n",
    "![](Fig/1.png \"Figure 1: The diagonal of a cube projected to a single point\")"
   ],
   "id": "770356d44345e508"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1101a45fa0f98f4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 Prokudin-Gorskii: Color from grayscale photographs [50 pts]",
   "id": "2f347b5ead627a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this part, you are tasked with implementing the dream of Russian photographer, Sergei Mikhailovich\n",
    "Prokudin-Gorskii (1863-1944), via a project invented by Russian-American vision researcher, Alexei A.\n",
    "Efros (1975-present). Sergei was a visionary who believed in a future with color photography (which we\n",
    "now take for granted). During his lifetime, he traveled across the Russian Empire taking photographs\n",
    "through custom color filters at the whim of the czar. To capture color for the photographers of the future,\n",
    "he decided to take three separate black-and-white pictures of every scene, each with a red, green, or blue\n",
    "color filter in front of the camera. His hope was that you, as a student in the future, would come along and\n",
    "produce beautiful color images by combining his 3 separate, filtered images."
   ],
   "id": "3f7e6456417d671e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1: Combine (5 pts) \n",
    "We will provide you with a folder of Prokudin-Gorskii’s black-and-white\n",
    "(grayscale) image composites (prokudin-gorskii/ in the assignment zip). Each composite (alter- natively\n",
    "triple-framed image or triptych) contains three grayscale photos preserved from the early 1900s. The\n",
    "composite looks like a three-panel vertical comic strip, with each grayscale photo in the composite\n",
    "positioned vertically above one another. These photos represent images captured with a blue, green, and\n",
    "red filter. Choose a single composite from this folder (your favorite) and write a program in Python that\n",
    "takes the three grayscale panels and simply stacks them across the third color channel dimension to\n",
    "produce a single, colored image. We expect this stacked photo to look wonky and unaligned- fixing this is\n",
    "what you will do in Task 2. Make sure to save your images as RGB instead of BGR and include them in\n",
    "your report.\n",
    "Specifically: Write a function that loads a grayscale tripled-framed image from prokudin-gorskii/ with\n",
    "something like plt.imread(), chops it vertically into thirds, then saves a color image with each third as the\n",
    "correct color channel. Save the output colored image in your report."
   ],
   "id": "16da28902e83455a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2: Alignment (25 pts) \n",
    "As you will have noticed, the photos are misaligned due to inadvertent\n",
    "jostling of the camera between each shot. Your second task is to fix this. You need to search over possible\n",
    "pixel offsets in the range of [-15, 15] to find the best alignment for the different R, G, and B channels.\n",
    "The simplest way is to keep one channel fixed, say R, and align the G and B channels to it by searching\n",
    "over the offset range both horizontally and vertically. Pick the alignment that maximizes a similarity\n",
    "metric (of your choice) between the channels. One such measure is dot product, i.e, R G. Another is\n",
    "normalized cross- correlation, which is simply the dot product between the L2 normalized R and G\n",
    "vectors. After writing this function, run it on all of the images in prokudin-gorskii/ and also on ’efros\n",
    "tableau.jpg’, so Professor Efros can have his photo restored to color. Include these aligned images and the\n",
    "offsets in your report. For full credit, your report needs to include properly aligned images - find a\n",
    "similarity metric that will accomplish this."
   ],
   "id": "3463bea4277f7bd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Specifically**: Write a function to align the 3 channels of the image produced by Task 1. This function\n",
    "should output the (x,y) offsets required for shifting two of the color channels with respect to third. The\n",
    "third channel might then have a (0,0) offset. Save the newly aligned images from prokudin-gorskii/ and\n",
    "’efros tableau.jpg’ in your report, along with the offsets for each color channel. Report the similarity\n",
    "metric you choose.\n",
    "\n",
    "**Hint**: To offset the channels while keeping the same dimensions among them, you can use either np.roll()\n",
    "to roll over boundaries, or np.pad() for padding."
   ],
   "id": "7f3e7c5d063af9f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3: Pyramid (20 pts) \n",
    "For very large offsets (and high-resolution images), comparing all the alignments\n",
    "for a broad range of displacements (e.g. [-30, 30]) can be computationally intensive. We will have\n",
    "you implement a recursive version of your algorithm that starts by estimating an image’s alignment on a\n",
    "low-resolution version of itself, before refining it on higher resolutions. To implement this, you will build\n",
    "a two-level image pyramid. To do this, you must first scale the triple-frame images down by a factor of 2\n",
    "(both the width and height should end up halved). Starting with your shrunk, coarse images, execute your\n",
    "alignment from Task 2 over the following range of offsets [-15, 15]. Choose the best alignment based on\n",
    "your similarity metric and treat it as the new current alignment. Then in the full resolution images, use\n",
    "this new current alignment as a starting place to again run the alignment from Task 2 in a small range [-\n",
    "15, 15]. Run this Pyramid task on the ’seoul tableau.jpg’ and ’vancouver tableau.jpg’ images. If your\n",
    "course project goes well.\n",
    "\n",
    "**Specifically**: Use cv2.resize() to shrink each image in the triptych. Use your code from Task 2 to align\n",
    "them and get the intermediate offset. Shift the original images accordingly and align again at full\n",
    "resolution. Report the intermediate offset (at the coarse resolution), the next offset at the full resolution,\n",
    "and what the overall total offset was that includes both of these. Save the aligned images in color in your\n",
    "report.\n",
    "\n",
    "**Hint**: If you’re struggling, use a different color channel as your anchor!\n",
    "\n",
    "**Report** You must submit a report that includes the offsets, color output images, and description required\n",
    "above. Your description should be such that a reader could implement what you’ve done after reading your\n",
    "report."
   ],
   "id": "2c36986ba72635ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c00533d0f774344a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Color Spaces and illuminance [20 pts]\n",
    "\n",
    "The same color may look different under different lighting conditions. Images indoor.png and outdoor.png are two photos of a\n",
    "same Rubik’s cube under different illuminances2.\n",
    "1. Load the images and plot their R, G, B channels separately as grayscale images using plt.imshow() (beware of\n",
    "normalization). Then convert them into LAB color space using cv2.cvtColor() and plot the three channels again. Include the\n",
    "plots in your report. (5 pts)\n",
    "2. How do you know the illuminance change is better separated in LAB color space? (5 pts)\n",
    "3. Choose two different lighting conditions and take two photos of a non-specular object. Try to make the same color look\n",
    "as different as possible (a large distance on AB plane in LAB space). Below is an example of two photos of the same piece\n",
    "of paper, taken in the basement and by the window respectively.\n",
    "\n",
    "\n",
    "Submit the two images with names im1.jpg and im2.jpg, both cropped and scaled to 256X256. Under the same folder, also\n",
    "submit a file info.txt that contains two lines: Line 1 contains four integers x1,y1,x2,y2 where we will take a 32X32 patch\n",
    "around the coordinate on each image and compare colors. (You can use plt.imshow() and plt.show() to bring up a window\n",
    "where you can select pixel with coordinates.) Line 2 is a description of the lighting conditions that you choose. An example of\n",
    "this file is provided for you in the folder. (10 pts)"
   ],
   "id": "72477f938601c2ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8b0682fde454ad40",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
